{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "? generale de banque sa lt ? br and lt heller overseas corp of chicago have each taken 50 pct stakes in ? company sa ? factors generale de banque said in a statement it gave no financial details of the transaction sa ? ? turnover in 1986 was 17 5 billion belgian francs reuter 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "? shr 3 28 dlrs vs 22 cts shr diluted 2 99 dlrs vs 22 cts net 46 0 mln vs 3 328 000 avg shrs 14 0 mln vs 15 2 mln year shr 5 41 dlrs vs 1 56 dlrs shr diluted 4 94 dlrs vs 1 50 dlrs net 78 2 mln vs 25 9 mln avg shrs 14 5 mln vs 15 1 mln note earnings per share reflect the two for one split effective january 6 1987 per share amounts are calculated after preferred stock dividends loss continuing operations for the qtr 1986 includes gains of sale of investments in ? corp of 14 mln dlrs and associated companies of 4 189 000 less writedowns of investments in national ? inc of 11 8 mln and ? corp of 15 6 mln reuter 3\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in train_data[:3]:\n",
    "    texto = \" \".join([reverse_word_index.get(i-3, '?') for i in data])\n",
    "    print(texto)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "# Number of categories\n",
    "num_classes = np.max(train_labels)+1\n",
    "\n",
    "\n",
    "\n",
    "unique_labels = set(train_labels)\n",
    "print(len(unique_labels))\n",
    "# print(train_labels)\n",
    "# print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize word indices\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words = 10000)\n",
    "train_data = tokenizer.sequences_to_matrix(train_data, mode='binary')\n",
    "test_data  = tokenizer.sequences_to_matrix(test_data, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to  categorical one hot encoding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "one_hot_train_labels = to_categorical(train_labels, num_classes)\n",
    "one_hot_test_labels = to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/20\n",
      "8083/8083 [==============================] - 3s 430us/step - loss: 3.2097 - acc: 0.4115 - val_loss: 2.5346 - val_acc: 0.5217\n",
      "Epoch 2/20\n",
      "8083/8083 [==============================] - 1s 185us/step - loss: 1.9402 - acc: 0.5820 - val_loss: 1.7111 - val_acc: 0.6429\n",
      "Epoch 3/20\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 1.3702 - acc: 0.7072 - val_loss: 1.4125 - val_acc: 0.7030\n",
      "Epoch 4/20\n",
      "8083/8083 [==============================] - 1s 151us/step - loss: 1.0738 - acc: 0.7674 - val_loss: 1.2576 - val_acc: 0.7264\n",
      "Epoch 5/20\n",
      "8083/8083 [==============================] - 1s 175us/step - loss: 0.8524 - acc: 0.8188 - val_loss: 1.1498 - val_acc: 0.7508\n",
      "Epoch 6/20\n",
      "8083/8083 [==============================] - 1s 184us/step - loss: 0.6709 - acc: 0.8591 - val_loss: 1.0833 - val_acc: 0.7675\n",
      "Epoch 7/20\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 0.5271 - acc: 0.8906 - val_loss: 1.0340 - val_acc: 0.7820\n",
      "Epoch 8/20\n",
      "8083/8083 [==============================] - 1s 150us/step - loss: 0.4115 - acc: 0.9115 - val_loss: 1.0006 - val_acc: 0.7987\n",
      "Epoch 9/20\n",
      "8083/8083 [==============================] - 1s 158us/step - loss: 0.3236 - acc: 0.9311 - val_loss: 0.9993 - val_acc: 0.7953\n",
      "Epoch 10/20\n",
      "8083/8083 [==============================] - 1s 171us/step - loss: 0.2640 - acc: 0.9400 - val_loss: 0.9816 - val_acc: 0.8042\n",
      "Epoch 11/20\n",
      "8083/8083 [==============================] - 1s 142us/step - loss: 0.2142 - acc: 0.9488 - val_loss: 0.9802 - val_acc: 0.7998\n",
      "Epoch 12/20\n",
      "8083/8083 [==============================] - 1s 149us/step - loss: 0.1849 - acc: 0.9546 - val_loss: 1.0173 - val_acc: 0.7942\n",
      "Epoch 13/20\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.1584 - acc: 0.9546 - val_loss: 1.0015 - val_acc: 0.8042\n",
      "Epoch 14/20\n",
      "8083/8083 [==============================] - 1s 169us/step - loss: 0.1407 - acc: 0.9597 - val_loss: 1.0380 - val_acc: 0.8031\n",
      "Epoch 15/20\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 0.1254 - acc: 0.9604 - val_loss: 1.0168 - val_acc: 0.7987\n",
      "Epoch 16/20\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 0.1180 - acc: 0.9602 - val_loss: 1.0587 - val_acc: 0.7898\n",
      "Epoch 17/20\n",
      "8083/8083 [==============================] - 1s 157us/step - loss: 0.1123 - acc: 0.9613 - val_loss: 1.0832 - val_acc: 0.7920\n",
      "Epoch 18/20\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 0.1049 - acc: 0.9638 - val_loss: 1.0859 - val_acc: 0.8020\n",
      "Epoch 19/20\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 0.1037 - acc: 0.9605 - val_loss: 1.1006 - val_acc: 0.7931\n",
      "Epoch 20/20\n",
      "8083/8083 [==============================] - 1s 154us/step - loss: 0.0944 - acc: 0.9634 - val_loss: 1.1069 - val_acc: 0.7953\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, one_hot_train_labels, batch_size=512, epochs=20, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 167us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data, one_hot_test_labels, batch_size=512, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 79.07%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: {}%\".format(str(score[1]*100)[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
